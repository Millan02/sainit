AWS Is a cloud service provider : 


Cloud Computing : NIST (National instiyute of standard and technology)..  : 

https://www.nist.gov/system/files/documents/itl/cloud/cloud-def-v15.pdf

Servers, Applications, Network, Database, storage..!!
--> AWS, Azure, GCP, orclae cloud, Rackspace, virtusteam, fujitsu, alibaba, tencent cloud, cloud9, Dell bhoomi..

--> On-demand : 
--> Broadnetwork access and High availability : 
--> Resource pooling : 
--> Rapid elasticity : (Scale up and Scale down)
--> Measured Services : 

Tenancy : 
Dedicated tenancy
Shared tenancy

Host Based Hypervisor :   H/w --> OS --> Virtualisation s/w --> o/s , o/s
Bare Metal Hypervisor :  H/W --> Hypervisor --> O/s, o/s



Deployment Models of the CLoud COmputing : 

Public CLoud : Open for everyone.. : AWS, Azure, GCP..  Maintenace : AWS.. 

Private Cloud : Dedicated for one Organisation.. : Maintenace: Your org / 3rd party..!!

Hybdrid Cloud : COmbination of multipe CLoud platforms : 
aws + azure : yes
aws + Onpremise : yes

COmmunity Cloud : Group of org build the infra, those group of org use that infra.. 

__

Service Model of the CLoud COmputing : 

SaaS : Lightsail
PaaS : Beanstalk
IaaS : ec2



How to Create an AWS Account.!!

https://aws.amazon.com/free

Step 1 : Provide Email, Password, COnfirm apssword, Account Name.

Step 2 : COntact Information
Name, Address, Ph number.

Step 3 : Payment information : CC/DC : Visa, master, AMEX, Discovery
2 INR.. Refund back..

Step 4 : Identity Verification : Phone verification and email verification.
Phone : Enter ph no , Call me now --> XXXX --> ANswet the call and enter XXX pin incall..

Step 5 : CHoose Support Plan  : BASIC

1. Account and Biling related : 24x7 support for all SP
2. Service limit increase : 24x7 support for all SP
3. Technical Support : Depends on SP

Basic SP : Free, No technical Support.. 7 core area checks on Trusted advisor
AWS Developer Forums, Knowledgebase articles (KBs)

Developer SP : 29$/Month.. 12-24 Local business hours AWS Support Associate.. 
7 core area checks on Trusted advisor.. Unlimited tickets / Primary contact can raise ticket..
Severity :
General guidance : < 24 Hrs
System impaired : < 12 Hrs

Business SP : 100$/Month.. 24x7 Phone, email, chat support from AWS Engineer.. 
Full trusted advisor checks.. Unlimited tickets/ Unlimited user can raise ticket..
Severity : 
General guidance : < 24 Hrs
System impaired : < 12 Hrs
Production system impaired : < 4 hrs
Production system down : < 1 Hr

Enterprise SP : 15k/Month.. 24x7 Phone, email, chat support from Sr. AWS Engineer.. 
Full trusted advisor checks.. Unlimited tickets/ Unlimited user can raise ticket..
--> Operational and Architectural reviews
--> Dedicated TAM (technical account Manager)
Severity : 
General guidance : < 24 Hrs
System impaired : < 12 Hrs
Production system impaired : < 4 hrs
Production system down : < 1 Hr
Business Critical system down : < 15 min

Review. 

Login to aws account.

_______________________________________________________________________________________
D: 22/05/2021

Enabled MFA on root account. 
--> Virtual MFA
--> u2f key / yubykey 
--> Hardware mfa

Root user : Unrestricted access on aws account. (Closing account, account transfer, Support plan change)

IAM : Identity and access management : used to perform day to day activities.


s3 : Simple storage service : AWS version of gdrive. 
ec2 : Elastic compute cloud :  We can launch and run servers : 


Least privilages mechanism : Provide the access to perform his job/duties.

avinash : s3 full access : IAM : Share his cred
anudeep : ec2 full access : IAM : 
 : TL : Admin access : 

IAM User creation : 

Step 1 : Choose User name 	: sai

Step 2 : Choose access type	: 

--> Management console : GUI : un, pwd & sign-in : Browser
--> programatic access : CLI : Accesskeyid & Secretaccesskey : sdk, cdk, api, 3rd party

Step 3 : Allocate permissions

--> Create a group, Add permissions at group level.. Add this user to group.
--> COpy settings from another IAM user.
--> Attach permissions on user.

Policy : Set of permissions on our aws account.

Step 4 : Add Tags

Step 5 : review and create


Birth settings : 
--> MFA
--> Setup strong password policy for IAM users


Policy : 
--> AWS Managed policy : We cannot delete
--> AWS Managed - Job function : we cannot delete
--> Customer Managed policy : 

** DENY always have highest priority. 
If you allow 100 time, but denied 1 time = DENY


Req: Provide access on S3 and ec2 services.

Requirement : IAM user with Administrator access.. but not on s3.. 


Implicit allow : What are all the services access we provide, he can access only those services. Remaining all services will deny automatically.

Explicit Deny : What are the service set as deny, that will be denied.. If you allow at any level (user, group, resurce), Deny will take effect.

Policy simulator : It can simulate IAM users permissions.

Cloudtrail : Logging service in AWS. It stores last 90 days activities. 

Credentials Report : Report on When user last logged in, When user created, password last used, password reset date.

arn : Amazon resource name : arn name gives uniqueness to our aws resources.


Task 1 : Create an IAM user with S3 fullAccess and login as IAM user and verify his access on S3, ec2 and iam. 	Exp: He should able to see only s3 w/o error.

___
Task 2 : Create an IAM user, with "AdministratorAccess". (use the same user througout course).

Task 3 : Login as task2 user.. And try to access "billing Information", It will show error/access denied.
Provide "billingaccess" to IAM user.
___

Task 4 : Create a new IAM User with S3 FullAccess.. 
Create a Policy to activate MFA himself.

___________________________________________________________________________________
Permissions Boundary : We can setup maximum permissions for an IAM user. 


Inline Policy : Policy for one single resource only. We cannot reuse this policy.


_______________________________________________________________________________________

S3: Simple Storage Sevice : 

--> Object based storage : We can store flat files / any files.
--> We store data in "Buckets"
--> Bucket nothing but a folder with unique name.
--> We can upload objects into bucket.
--> We can create 100 buckets in s3 platform by defaultly. (TO increase count raise service limit increase ticket)
--> Bucket naming Limitation :
	--> Should not start with . / Should not end with . / no adjesent ..
	--> Only Small characters / No Capital letters
	--> bucket name should not resemble IP address format.

--> S3 have unlimited data.
--> S3 supports max Object size : 5 TB, Min Obj size: 0/1 byte

Publicly accessable S3 Object URL : 
https://s3.regioncode.amazonaws.com/bucketname/objectname

Virtual Path: Works when we don't have . in the bucket name

https://bucketname.s3.regioncode.amazonaws.com/objectname
https://bucketname.s3.amazonaws.com/objectname


To make any object public, We need to Modify the bucket level settings, then object level settings.

Block all public access : --> OFF
Go to object promperty --> Make Public. 

___

S3 Standard : Default storage class.. Designed to store Frequently accessed data.. 
Data will be available immediately.. 
Data Spread across >= 3 AZs..
Availa: 99.99% , DUrability : 99.999999999% (11 9's)

Standard IA : Designed to store less freq accessed data.. 
Data will be available immediately.. 
Data Spread across >= 3 AZs..
Availa: 99.9% , Durability : 99.999999999% (11 9's)

OneZone-IA : Designed to store less freq accessed data.. 
Data will be available immediately.. 
Data Spread across 1 AZs..
Availa: 99.5% , Durability : 99.999999999% (11 9's)

GLacier : Designed to store data for longer durations.. FOr Archiving the data..
Data will not be avaibale immedetaly. We need to initiate "Restoration". 
Restoration takes MINUTES - HOURS.
Data Spread across >= 3 AZs..
Availa: 99.99% , Durability : 99.999999999% (11 9's)

Glacier Deep archieve : Designed to store data for longer durations.. FOr Archiving the data.. Data will not be avaibale immedetaly. We need to initiate "Restoration". 
Restoration takes Min HOURS.
Data Spread across >= 3 AZs..
Availa: 99.99% , Durability : 99.999999999% (11 9's)

Interlligent Tier : When we have unknown access patterns for our data.. No idea on how freq we access data.. 
Data Spread across >= 3 AZs..
Availa: 99.9% , Durability : 99.999999999% (11 9's)

RRS : Redused Redunancy storage : Not used : Chances to loss the data is more.. it cost more than S3 standard.. Easily reprodusable data we can store here.. Logs/thumbnails.. 
Durability is Justn 99.99% only.. 

_____

Retrieval tier

Bulk retrieval : Typically within 5-12 hours.
Standard retrieval: Typically within 3-5 hours.
Expedited retrieval : Typically within 1-5 minutes when retrieving less than 250 MB.

_____

FREE TIER ELIGIBILITY : 5 gb Standard storage.. 
2000 PUT Operations, 20,000 GET Operations comes under free tier.. / Month

_______________________

Amazon Segrigated entire world into regions. They named all the regions.

Region : geoGraphical location / Physical location.  25 Regions (May 2021)
Mumbai : ap-south-1
Hyd : ap-south-2
N V : us-east-1

Availability ZOne / AZs : Data Center / Combination of Multiple DCs.. Our resources actually runs here (instance, db).. 80 AZs..
--> Every Region contains Min of 2 AZs. 

Mumbai : ap-south-1a, ap-south-1b & ap-south-1c
hyd : ap-south-a2, 2b & 2c

Edge locations : CDN Endpoint / Cache locations.. 230+ Edge locations.. 

_______________________________________________________________________________________
D: 24/05/2021

Versioning : 
--> We can track all changes happening on this file.
--> If we accidentally deleted the object, we can get it back if versioning is enabled.

Most recent uploaded object called as "Current Object / Latest object"

(version: hide)
When versioning is enabled, If we delete the object, we will get the "Delete Marker", Delete the Delete marker to get this object back to s3 bucket.

(version: show)
Whatever we deletes, we won;t get any delate marker. Object deletes permanently.


delete : Create a Delete Marker.
permanently delete : THis object deletes permanently, without delete marker.

_____
LCR : LifeCycle Management Rule : 

expire : We will get a Delete marker.


_____

CRR/SRR : 
--> Source bucket and Destination bucket should enabled with Versioning.
--> If source bucket and destination bucket is in same region : SRR (Same region replicaiton)
--> If source and destination buckets are in diff region : CRR (Cross region replication).

RTC : Replication Time Control : Boost up the replication process. Max of data replicates within 15 min. 

--> Existing objects won't replicate to destination bucket. All future/subsequent uploads will replicate to destination bucket.

______
Create a Billing Alarm to get notification when any of the aws resource start costing us.
Billing preference --> Receive Billing Alerts -->  Manage Billing Alerts  --> create a billing alarm.

________________

Intelligent tier :

Archive Access tier : When enabled, Intelligent-Tiering will automatically move objects that haven’t been accessed for a minimum of 90 days to the Archive Access tier.

Deep Archive Access tier : When enabled, Intelligent-Tiering will automatically move objects that haven’t been accessed for a minimum of 180 days to the Deep Archive Access tier.

______________

Server access logging : Enable logging for this bucket. 

______________

Event : When any specific operation happened on our s3 bucket, we can trigger another services.

--> SNS : Simple Notification Service
--> SQS : Simple Queue Service
--> Lambda 

Step 1 : create an SNS topic, Add subnscribers to SNS topic. (Set permissions to everyone).
Step 2 : Configure Events via SNS.

_________________________________________

Task 1 : ENable Versioning, Explore versioning.

Task 2 : Configure LCR to Transit all Current Versioned object "S3-Standard" --> Standard-IA after 10 Days --> Delete after 20 Days.
100 Days --> Delete after 200 Days.

Previous versioned objects : S3-Stanard --> Delete after 1 Day.

Task 3 : Create "bucket 1" and "bucket 2" in Mumbai region.. Configure the Replication between these buckets.

Task 4 : Create an SNS topic, add email as subscribers.. COnfigure "PUT" Event notification on s3 bucket.

_________________________________________

Transfer acceleration : S3 uses nearby edge locations to upload / download the data if this feature is enabled.

When geograhical distance increase, latency also increases.
We have tracert / traceroute command to know the internet route.

https://s3-accelerate-speedtest.s3-accelerate.amazonaws.com/en/accelerate-speed-comparsion.html
--> We should not have . in the bucket name to use this feature.

___

Object Lock : Security feature aws introdused recently. 
--> We need to enable this while creating s3 bucket.
--> For an existing bucket, if you want to enable, we need to contact AWS.
--> Versioning must be enabled. 

Governance : Users with specific IAM permissions can overwrite or delete protected object versions during the retention period.

Compliance : No users can overwrite or delete protected object versions during the retention period. (inclusing root user).

__

Requester pays : Instead of bucket owner, data requester need pay. Requester will pay for requests and data transfer. While requester pays is enabled, anonymous access to this bucket is disabled.

___

Static website hosting : 
--> S3 supports only static website hosting.
--> if future if you want to map a DOmain Name, 
--> DOmain name should be same as Bucketname.
--> Most of the times it's written in html.
--> S3 bucket data should be made as "Public Read", then only this feature works.

http://avinash.com.s3-website.ap-south-1.amazonaws.com


http status codes : 

2XX : OK / Success
3XX : Redirection error
4XX : CLient Side error
5XX : Server Side error

____

WE have a dedicated service called "Cloudwatch" to provide metrics on our aws resources.
--> It provides graphical overview for the resources.


Storage Class Analysis : Analyze storage access patterns to help you decide when to transition objects to the appropriate storage class.

Inventory configurations : You can create inventory configurations on a bucket to generate a flat file list of your objects and metadata. These scheduled reports can include all objects in the bucket or be limited to a shared prefix.


metadata : data about the data. Using Tags we can provide metadata to any of the resource in AWS.

Task : Create a static website and deliver. 
https://www.free-css.com/free-css-templates

Task 2 : Try Object lock feature.

________________________________________________________________________________________

D: 25/05/2021

Encryption : 

--> In-Transit Encryption
	--> S3 Uses SSL / TLS Certificates. THis enabled by defaultly.

--> Server Side Encryption (SSE) / At-Rest 
	--> SSE - S3 : Key material generated and managed by S3 platform. Whoever have valid access on s3 platform they can decrypt the data.

    --> SSE - KMS (Key Management Service): 
	--> aws/s3 : (Default Master Key / DMK) : Key material generated and managed by KMS Service. Whoever have valid access on s3 platform they can decrypt the data.
	--> Customer managed keys (CMK) : Key material generated and managed by KMS Service. We need to provide required permissions on Encryption key to IAM users/Roles, then only they can decrypt the data. (NO FREE TIER ELIGIBILITY : 1$/Month)

	--> SSE - C (Customer Provided) : We/customer need to generate the key material and need to upload the key material to KMS service, then we can use as regular kms key. We need to provide required permissions on Encryption key to IAM users/Roles, then only they can decrypt the data. (NO FREE TIER ELIGIBILITY : 1$/Month)


Client SIde Encryption : When client don;t want to send any unencrypted data to any of the outside env, We can use this CSE. AWS is not responsible for this CSE. (truecrypt, securedata)

_____
KMS Defaultly generates the Key for the services we are using (Ex: aws/s3, aws/ebs, aws/efs). These keys we cannot delete, It is managed by AWS KMS service.

Step 1 : Symmetric 
Symmetric : A single encryption key that is used for both encrypt and decrypt operations
Asymmetric : A public and private key pair that can be used for encrypt/decrypt or sign/verify operat.

Step 2: provid name and descryption.

Step 3: Define key administrative permissions. 
	--> Who can administrate this encryption key. (Delete, Provide permission to users, key disable/enable).

Step 4 : Define key usage permissions
	--> Who can use this key. Who can decrypt the data. 

Step 5 : Review and create.

___________

Bucket Policy : 

Avinash_T : S3 Full Access : 
testuser : S3 Full Access :

1avinash : testuser should not get any chance to upload the data. / Deny "Upload/PUT" for testuser to 1avinash bucket..!!!

--> Bucket Policy generator: https://awspolicygen.s3.amazonaws.com/policygen.html

effect : ALLOW / DENY	: Deny
Principal : For what IAM user ARN : arn:aws:iam::518084852393:user/testuser
Actions : put Object
Resource ARN : On what s3 bucket : arn:aws:s3:::1avinash/*


/*	--> If it is an Object level operation.
	--> If it ia a bucket level operation.

_________

AWS Import / Expore : When we have large set of data to upload/download from AWS, we can use AWS own devices. AWS Snowfamily devices.

AWS Snowcone : 8 TB
AWS Snowball edge : 40 TB - 100 TB
AWS Snowmobile : PB Scale container


digiglobe => Snowmobile 
1 PB = 1 gbps --> 20-22 Yrs to uplaoad the data
Within 3 Months We can migrate 1 PB data

_____________________

User1 : S3 FUll ACCESS
User2 : S3 Full Access

"Sai-Bucket"

FOr USer1 --> DENY "Delete Bucket", "Deny PUTObject", "Deny view/putBUCKETPolicy"
For User2 --> He should able to upload the data, Should able to view bucket policy.

____

You have multiple buckets in S3 Platform.. You want to Allocate "user1bucket" to "user1" only... 
https://aws.amazon.com/premiumsupport/knowledge-center/s3-console-access-certain-bucket/


____________________________________________________________________________________________________________________________________________________________________

D: 26/05/2021


S3 Performance : 
--> If we are storing all the data in an s3 bucket.. 3500 PUT/Sec... 5500 GET/Sec.. 

These value applicable per prefix (Folder):

Per second 35,000, Create 10 prefixes and upload the data..

Bucket/FOlder1 -->  3500 PUT/Sec... 5500 GET/Sec..
bucket/Folder2 -->  3500 PUT/Sec... 5500 GET/Sec..

Increase the randomness on the object names for better performance. 
Use folder/Prefixes in s3 to get maximum performance.

_____

Read after writre consistenacy for put of new objects.
Eventual consistency for overwrite of PUTS and Delete. (it will take some seconds to delete the backend copies).

______________________________________________________________________________________________________________________________________________________________________


EC2 : Elastic Compute Cloud : Where we launch our instances.

Instance = Server (It contains OS, CPU, RAM/Memory, Storage, Network)

Traditional Method : We need to purchase the serverfirst.. Server Rack.. Power connectivity, Cooling systems, Physical security, Network devices.. 
--> Install Operating system, APplications/webservers.. Deploy your code --> Application deliver to end customer.
--> Once you done with the requirement, what you do with the resources..????

--> Launch an ec2 instance --> COnnect to Instance --> Deploy your code --> Deliver your application.
--> Once you done with the requirement, Terminate the respource and pay for the duration you have used. (pay-as-you-go).


On-Demand ec2 instances : When we don't have stable workloads, If you want to test your application for the first time, Non predictable workloads.. 
Price: /Hr basis.. (/Sec basis also)

Reserved ec2 instances : If we have predictable workloads.. If you want to run application for longer durations with aws.. COst less compared to On-demand.
Duration: 1 yr / 3 yrs.

	Standard RI : We cannot change the configuration.
	COnvertable RI : We can chnage the configuration during the period.
	Schedured RI : When we have persistant requests / Repeated requests with in duration (Ex: Weekly 40 hrs.. MON-FRI, Monthly 1-15th)

Pricing : Full Upfront : Need to pay 100% amount as onetime. No need to pay again.
	  Partial upfront : Pay 30-50% as onetime cost, Pay remaining amount on monthly basis based on your usage.
	  No upfront : No need to pay anything as upfront. Pay everything monthly basis.


Spot ec2 instances : If we have flexible start and stop durations, then only we choose spot instances. IF price is increased by AWS, we lost our ec2 instance. We don't run production worklods / Imp data on this spot instances.

1$/hr.. Hey aws, your cost is too high,, if you are okay to give this instance at 0.50$ from today to 30/05/2021. i will take this instance.. : BID to aws.
--> 
if your bid price is more than aws spot price or equal to aws spot price, we will get ec2 instance.

--> If Price is increased and AWS terminated our instance, we need to pay for only completed hours, not for the partial hours.
--> If Price is Not increased and YOU terminated our instance, we need to pay for total duration.

1 Hr 30 Min : YOu teminated : 1 Hr 30 Min
1 hr 30 Min : AWS terminated : 1 Hr

FREE TIER : 750 Hrs/Month with t2.micro WIndows Instance
750 Hrs/Month with t2.micro Linux Instance

__________________________________________________________


Step 1 : Choose an AMI (Amazon machine Image)		: Operating System

Step 2 : Choose Instance type (vCPU, Memory)		: COnfiguration

Step 3 : COnfigure additional settings

--> No of req instances, IAM Role, VPC, Userdata 
--> Shutdown behavior : What should happen when we choose shutdown option at OS level : STOP / Terminate.  : STOP.
--> Enable termination protection : ENABLE

Step 4 : Choose the STorage				: Storage for instance

Step 5 : Add required Tags (Key and Value)

Step 6 : Choose the Security Group 			: Firewall at instance level.

Windows : RDP (Remote Desktop Protocol) : 3389 : 
Linux : SSH (Secure Shell) : 22
http : Hypertext transfer protocol : 80
https : Secure over http : 443

Custom : Any network IP address
Anywhere : 0.0.0.0/0
my IP : Currently connected network public IP address. 

CLient Network IP : 202.153.35.250/32

Step 7 : Review and launch instance using a Keypair (.pem)

Keypair works with Encryption Decryption mechanism. 
--> AWS Keeps the Public Key and it copy the public keyin our dc2 instance.
--> We will have Private Key. If you want to get the password to get connect to the instance, Browse the "privatekey", then only we will get Password.


--> EC2 is a Region specific service. 
WIndows Instane Launch: 

t2.micro : Only t2.micro comes under free tier eligibility (1 vCPU, 1 RAM)

______


General Purpose : Stable/balanced performance of compute, memory and network resources.
Type : t2, t3, m5

Compute Optimized : We will get more CPU performances from these instances. We will have high perf processors in these instances.
Type : c4, c5, c6  (Compute / CPU)

Memory Optimized : We will get more RAM perf. Workloads required to process large set of data via memory.
Type : r4, r5, r6, x1, z1 (RAM)

GPU Optimized / Accelerated computing : We will get more graphic processings, Efficient for data pattern matching, High level gaming.
Type : p2, p3, p4, g3, g4, f1

Storage optimized : we will get more Storage/ Hard Disk performance. FOr the application required more IOPS, we use this types.
Type : d2, d3, i3

___________________________

To Connect to Windows Instances : 

Windows : Open "run" --> Type "mstsc" (Microsoft Terminal Service console) --> Enter.

MacBook : 

Public Ip address : unique across the globe. : Always use Public IP to connect.
Private ip address : unique with in the network.

--> When we connect to the instance, We can Setup customPassword, then we no need to use the keypair.


Task : Launch a Windows Instance, COnnect to it, Change the Wallpaper, Setup custom password.. Disconnect from the instance. 
Try to login to ec2 instance using "Keypair" given password.. Working or not..???
After connecting to instance, verify you have all data / wp or not..???












































































































































